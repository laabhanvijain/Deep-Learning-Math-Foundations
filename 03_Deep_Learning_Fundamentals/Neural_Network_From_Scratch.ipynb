{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Q1.** \n",
        "Implement a simple 3 layer neural network to be trained on MNIST dataset, but now you have to write the complete backward pass as well. The model class should have both `forward` and `backward` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hP15_2ZNBHYJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mGpv4z2JXoXg"
      },
      "outputs": [],
      "source": [
        "#prepare data (dataset, dataloader)\n",
        "#design model, neuralnet 3 layers\n",
        "#loss and backprop\n",
        "# training loop (forward, loss, backward, update)\n",
        "\n",
        "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#HYPERPARAMETERS\n",
        "batch_size= 100\n",
        "num_epochs= 10\n",
        "learning_rate=0.001\n",
        "input_size= 28*28\n",
        "hidden_size= 120\n",
        "num_classes= 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m-imv69BcrDI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:18<00:00, 522kB/s] \n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 77.8kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:06<00:00, 255kB/s] \n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.80MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset= torchvision.datasets.MNIST('root=./MNIST_DATA', train= True,\n",
        "                                          transform=transforms.ToTensor(), download= True)\n",
        "test_dataset= torchvision.datasets.MNIST('root=./MNIST_DATA', train= False,\n",
        "                                          transform=transforms.ToTensor(), download= True)\n",
        "train_loader= torch.utils.data.DataLoader(dataset=train_dataset, batch_size= batch_size,\n",
        "                                          shuffle=True)\n",
        "test_loader= torch.utils.data.DataLoader(dataset=test_dataset, batch_size= batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C6mM07gtWSO8"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0,x)  #max gives scalar\n",
        "\n",
        "def softmax(x):\n",
        "  o= np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "  return o\n",
        "\n",
        "def derivative_relu(x):\n",
        "  return x>0        #cant write if(x>0): return 1 else: return 0 as x is vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TLrzsLtsdWSR"
      },
      "outputs": [],
      "source": [
        "class NeuralNet3_model(nn.Module):\n",
        "  def __init__(self, input_size=input_size, hidden_size= hidden_size, num_classes=num_classes, batch_size=batch_size, learning_rate=learning_rate) -> None:\n",
        "    super(NeuralNet3_model, self).__init__()\n",
        "    self.batch_size= batch_size\n",
        "    self.learning_rate= learning_rate\n",
        "    self.w1=np.random.randn(input_size, hidden_size)\n",
        "    self.w2=np.random.randn(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x=x\n",
        "    self.z1= self.w1.T.dot(x)\n",
        "    self.a1= relu(self.z1)\n",
        "    self.z2= self.w2.T.dot(self.a1)\n",
        "    self.output= softmax(self.z2)\n",
        "    return self.output\n",
        "\n",
        "  def backward_weight_upd(self,actual_label):\n",
        "      # softmax + cross-entropyloss\n",
        "      dl_dz2= self.output - actual_label # IMP one hot encoding mein\n",
        "      dl_dw2= (1/self.batch_size)*(self.a1.dot(dl_dz2.T))\n",
        "      dl_da1= self.w2.dot(dl_dz2)\n",
        "      dl_dz1= dl_da1 * derivative_relu(self.z1)\n",
        "      dl_dw1=(1/self.batch_size)*(self.x.dot(dl_dz1.T))\n",
        "      alpha = self.learning_rate\n",
        "      self.w1 -= alpha * dl_dw1\n",
        "      self.w2 -= alpha * dl_dw2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7z7osqXVi6YG"
      },
      "outputs": [],
      "source": [
        "def image_convert(x):\n",
        "  # x=x.squeeze(1)\n",
        "  x=x.view(batch_size,-1)\n",
        "  x=x.T\n",
        "  x=x.numpy()\n",
        "  return (x)\n",
        "def convert_one_hot(y):\n",
        "  one_hot = np.zeros((10, y.shape[0]))\n",
        "  one_hot[y, np.arange(y.shape[0])] = 1\n",
        "  return one_hot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kRSQ-WvigoDi"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet3_model()\n",
        "img, label = next(iter(train_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpIXjky7tr13",
        "outputId": "e10174bb-5b4b-4625-c539-9e1b14b1a8c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] - Loss: 16.6037\n",
            "Epoch [2/10] - Loss: 11.2343\n",
            "Epoch [3/10] - Loss: 8.9051\n",
            "Epoch [4/10] - Loss: 7.5706\n",
            "Epoch [5/10] - Loss: 6.6979\n",
            "Epoch [6/10] - Loss: 6.0712\n",
            "Epoch [7/10] - Loss: 5.5896\n",
            "Epoch [8/10] - Loss: 5.2020\n",
            "Epoch [9/10] - Loss: 4.8759\n",
            "Epoch [10/10] - Loss: 4.6067\n"
          ]
        }
      ],
      "source": [
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    epsilon = 1e-12      # Avoid log(0)\n",
        "    loss = -np.sum(y_true * np.log(y_pred + epsilon)) / y_true.shape[1]\n",
        "    return loss\n",
        "\n",
        "# TRAINING LOOP\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for img_batch, label_batch in train_loader:\n",
        "        x = image_convert(img_batch)\n",
        "        y = convert_one_hot(label_batch.numpy())\n",
        "        prediction = model.forward(x)\n",
        "        loss = cross_entropy_loss(prediction, y)\n",
        "        total_loss += loss\n",
        "        model.backward_weight_upd(y)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q58Vi0UIu0-T",
        "outputId": "a2c06b44-57ea-4353-f3c0-aea94a12553f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 75.85%\n"
          ]
        }
      ],
      "source": [
        "def accuracy(predictions, targets):\n",
        "    predicted_classes = np.argmax(predictions, axis=0)\n",
        "    actual_classes = np.argmax(targets, axis=0)\n",
        "    return np.mean(predicted_classes == actual_classes) * 100\n",
        "\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "num_test_batches = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    x = image_convert(images)\n",
        "    y = convert_one_hot(labels)\n",
        "    predictions = model.forward(x)\n",
        "\n",
        "\n",
        "    loss = cross_entropy_loss(predictions, y)\n",
        "    accuracyy = accuracy(predictions, y)\n",
        "\n",
        "    test_loss += loss\n",
        "    test_accuracy += accuracyy\n",
        "    num_test_batches += 1\n",
        "\n",
        "avg_test_accuracy = test_accuracy / num_test_batches\n",
        "\n",
        "print(f\"Test Accuracy: {avg_test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgrNvGAOyBtV"
      },
      "source": [
        "Getting:<br/>\n",
        "Epoch [1/10] - Loss: 19.1906\n",
        "\n",
        "Epoch [2/10] - Loss: 11.6504\n",
        "\n",
        "Epoch [3/10] - Loss: 8.7364\n",
        "\n",
        "Epoch [4/10] - Loss: 7.2344\n",
        "\n",
        "Epoch [5/10] - Loss: 6.2795\n",
        "\n",
        "Epoch [6/10] - Loss: 5.6161\n",
        "\n",
        "Epoch [7/10] - Loss: 5.1319\n",
        "\n",
        "Epoch [8/10] - Loss: 4.7632\n",
        "\n",
        "Epoch [9/10] - Loss: 4.4675\n",
        "\n",
        "Epoch [10/10] - Loss: 4.2235\n",
        "\n",
        "\n",
        "Test Accuracy: 76.43%"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
